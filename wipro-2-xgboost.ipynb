{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c94c3e5",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-04-12T14:38:16.964459Z",
     "iopub.status.busy": "2023-04-12T14:38:16.963614Z",
     "iopub.status.idle": "2023-04-12T14:38:20.479669Z",
     "shell.execute_reply": "2023-04-12T14:38:20.478349Z"
    },
    "papermill": {
     "duration": 3.526073,
     "end_time": "2023-04-12T14:38:20.482671",
     "exception": false,
     "start_time": "2023-04-12T14:38:16.956598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_validate, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, SCORERS\n",
    "from xgboost import XGBRegressor,XGBClassifier\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef81037f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-12T14:38:20.492933Z",
     "iopub.status.busy": "2023-04-12T14:38:20.492599Z",
     "iopub.status.idle": "2023-04-12T14:38:20.983863Z",
     "shell.execute_reply": "2023-04-12T14:38:20.982710Z"
    },
    "papermill": {
     "duration": 0.499437,
     "end_time": "2023-04-12T14:38:20.986776",
     "exception": false,
     "start_time": "2023-04-12T14:38:20.487339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#data prep\n",
    "trainset = pd.read_csv(\"/kaggle/input/mh-wipro-sustainable-ml-challenge/train.csv\")\n",
    "testset = pd.read_csv(\"/kaggle/input/mh-wipro-sustainable-ml-challenge/test.csv\")\n",
    "\n",
    "test = testset.drop(['Clearsky DHI', 'Clearsky DNI', 'Clearsky GHI'],axis = 1)\n",
    "\n",
    "Y_cols = trainset.loc[:, ['Clearsky DHI', 'Clearsky DNI', 'Clearsky GHI']]\n",
    "trainset = trainset.drop(['Clearsky DHI', 'Clearsky DNI', 'Clearsky GHI'], axis = 1)\n",
    "\n",
    "train_dhi = Y_cols['Clearsky DHI']\n",
    "train_dni = Y_cols['Clearsky DNI']\n",
    "train_ghi = Y_cols['Clearsky GHI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "765b72ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-12T14:38:20.998632Z",
     "iopub.status.busy": "2023-04-12T14:38:20.998246Z",
     "iopub.status.idle": "2023-04-12T14:38:21.008152Z",
     "shell.execute_reply": "2023-04-12T14:38:21.006996Z"
    },
    "papermill": {
     "duration": 0.018506,
     "end_time": "2023-04-12T14:38:21.010671",
     "exception": false,
     "start_time": "2023-04-12T14:38:20.992165",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year                    int64\n",
       "Month                   int64\n",
       "Day                     int64\n",
       "Hour                    int64\n",
       "Minute                  int64\n",
       "Cloud Type              int64\n",
       "Dew Point             float64\n",
       "Temperature           float64\n",
       "Pressure                int64\n",
       "Relative Humidity     float64\n",
       "Solar Zenith Angle    float64\n",
       "Precipitable Water    float64\n",
       "Wind Direction        float64\n",
       "Wind Speed            float64\n",
       "Fill Flag               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b6a7b3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-12T14:38:21.022888Z",
     "iopub.status.busy": "2023-04-12T14:38:21.021830Z",
     "iopub.status.idle": "2023-04-12T14:38:21.029519Z",
     "shell.execute_reply": "2023-04-12T14:38:21.028237Z"
    },
    "papermill": {
     "duration": 0.016533,
     "end_time": "2023-04-12T14:38:21.032132",
     "exception": false,
     "start_time": "2023-04-12T14:38:21.015599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dhi.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6f1ed24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-12T14:38:21.043282Z",
     "iopub.status.busy": "2023-04-12T14:38:21.043025Z",
     "iopub.status.idle": "2023-04-12T14:38:21.057821Z",
     "shell.execute_reply": "2023-04-12T14:38:21.056915Z"
    },
    "papermill": {
     "duration": 0.023174,
     "end_time": "2023-04-12T14:38:21.060191",
     "exception": false,
     "start_time": "2023-04-12T14:38:21.037017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Train:\n",
    "    def __init__(self, data, target, save_name):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "        self.save_name = save_name\n",
    "        \n",
    "    def objective(self, trial):\n",
    "        param = {\n",
    "            'verbosity': 1,\n",
    "            'objective': 'reg:squarederror',\n",
    "            'booster': trial.suggest_categorical('booster', ['gbtree', 'gblinear', 'dart']),\n",
    "            'lambda': trial.suggest_float('lambda', 1e-8, 1.0, log = True),\n",
    "            'alpha': trial.suggest_float('alpha', 1e-8, 1.0, log = True),\n",
    "            'eta': trial.suggest_float('eta', 1e-8, 1.0, log = True),\n",
    "            'gamma': trial.suggest_float('gamma', 1e-8, 10.0, log = True),\n",
    "                'max_depth': trial.suggest_int('max_depth', 5, 10),\n",
    "            'eval_metric': 'rmse',\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 200),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 1e-5, 9e-1, log = True),\n",
    "            'subsample': trial.suggest_float('subsample', 1e-5, 1),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 1e-5, 1)\n",
    "        }\n",
    "        model = XGBRegressor(tree_method=\"gpu_hist\",\n",
    "            gpu_id=0,\n",
    "            predictor=\"gpu_predictor\",**param)\n",
    "        val = cross_validate(model, self.data, self.target , scoring = 'neg_mean_squared_error', n_jobs = -1)\n",
    "        loss = np.mean(val['test_score'])\n",
    "        return loss\n",
    "\n",
    "    def study(self):\n",
    "        s = optuna.create_study(direction='maximize')\n",
    "        s.optimize(self.objective, n_trials=8)\n",
    "        return s.best_params\n",
    "\n",
    "    def train_loop(self):\n",
    "        kf = KFold(shuffle = True, random_state = 42)\n",
    "        best_loss = 1e18\n",
    "        oof_preds = pd.DataFrame(columns = ['tar'], index = trainset.index)\n",
    "\n",
    "        params = self.study()\n",
    "        model = XGBRegressor(tree_method = 'gpu_hist', gpu_id = 0, predictor = \"gpu_predictor\",**params)\n",
    "        print(\"Training starts...\")\n",
    "        for fold, (train_idx, test_idx) in enumerate(kf.split(self.data, self.target)):\n",
    "            print(\"fold_\",fold,\" done !\")\n",
    "            xt = trainset.iloc[train_idx, :]\n",
    "            yt = train_dhi.iloc[train_idx]\n",
    "            xv = trainset.iloc[test_idx, :]\n",
    "            yv = train_dhi.iloc[test_idx]\n",
    "            model.fit(xt, yt)\n",
    "            pred = model.predict(xv)\n",
    "            loss = mean_squared_error(yv, pred)\n",
    "\n",
    "            oof_preds.loc[test_idx,'tar'] = pred #properly keeping oof preditcions according to test idx\n",
    "\n",
    "            filename = self.save_name+\".json\"\n",
    "            if(loss<best_loss):\n",
    "#                 model.save_model(self.save_name+\".json\")\n",
    "                pickle.dump(model, open(filename, \"wb\"))\n",
    "                best_loss = loss\n",
    "        \n",
    "        return oof_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89581975",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-12T14:38:21.070290Z",
     "iopub.status.busy": "2023-04-12T14:38:21.070032Z",
     "iopub.status.idle": "2023-04-12T14:41:45.192084Z",
     "shell.execute_reply": "2023-04-12T14:41:45.190845Z"
    },
    "papermill": {
     "duration": 204.130229,
     "end_time": "2023-04-12T14:41:45.194821",
     "exception": false,
     "start_time": "2023-04-12T14:38:21.064592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-12 14:38:21,079]\u001b[0m A new study created in memory with name: no-name-cfbee109-152e-403f-ace8-f9eaa91881e5\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 14:39:01,651]\u001b[0m Trial 0 finished with value: -451.45316439907435 and parameters: {'booster': 'gbtree', 'lambda': 0.04963428514251636, 'alpha': 0.0016729162206134687, 'eta': 0.03411385299897043, 'gamma': 8.778462725252736e-07, 'max_depth': 9, 'n_estimators': 183, 'learning_rate': 0.5902054790496137, 'subsample': 0.9826100621520778, 'colsample_bytree': 0.6853282558656341}. Best is trial 0 with value: -451.45316439907435.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 14:39:14,014]\u001b[0m Trial 1 finished with value: -1450.9228880118103 and parameters: {'booster': 'gblinear', 'lambda': 9.805004475155398e-07, 'alpha': 4.00362329682322e-05, 'eta': 7.549602456960428e-05, 'gamma': 1.4714213796502855e-08, 'max_depth': 6, 'n_estimators': 158, 'learning_rate': 0.06623118772032435, 'subsample': 0.21241574536949145, 'colsample_bytree': 0.9425640425829985}. Best is trial 0 with value: -451.45316439907435.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 14:39:22,877]\u001b[0m Trial 2 finished with value: -316.90141149300024 and parameters: {'booster': 'gbtree', 'lambda': 0.004967153075084659, 'alpha': 0.05247988014208934, 'eta': 0.048218314638502, 'gamma': 0.0006473599007684745, 'max_depth': 9, 'n_estimators': 132, 'learning_rate': 0.027782549344110966, 'subsample': 0.0020355951282173385, 'colsample_bytree': 0.7844258515433135}. Best is trial 2 with value: -316.90141149300024.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 14:39:32,909]\u001b[0m Trial 3 finished with value: -6700.433569892608 and parameters: {'booster': 'gblinear', 'lambda': 0.06579207479730219, 'alpha': 0.5816291054152226, 'eta': 0.00014262658259714167, 'gamma': 2.1499646290438496e-05, 'max_depth': 7, 'n_estimators': 122, 'learning_rate': 2.1107538280975043e-05, 'subsample': 0.2180442670266427, 'colsample_bytree': 0.4211153559899367}. Best is trial 2 with value: -316.90141149300024.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 14:39:44,813]\u001b[0m Trial 4 finished with value: -1799.9344631492236 and parameters: {'booster': 'gblinear', 'lambda': 2.799308577992997e-06, 'alpha': 9.047223572868382e-06, 'eta': 0.0067896310036334685, 'gamma': 8.131667569124694, 'max_depth': 6, 'n_estimators': 151, 'learning_rate': 0.010346562400163191, 'subsample': 0.4705375540087655, 'colsample_bytree': 0.23646637582129357}. Best is trial 2 with value: -316.90141149300024.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 14:41:01,113]\u001b[0m Trial 5 finished with value: -6563.951555720404 and parameters: {'booster': 'dart', 'lambda': 2.2687460957221068e-05, 'alpha': 0.040826275169815476, 'eta': 8.232122543406908e-06, 'gamma': 0.6168616302061002, 'max_depth': 6, 'n_estimators': 184, 'learning_rate': 0.00016675467392231481, 'subsample': 0.7603516362682973, 'colsample_bytree': 0.3794861439519321}. Best is trial 2 with value: -316.90141149300024.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 14:41:33,456]\u001b[0m Trial 6 finished with value: -6818.684753548213 and parameters: {'booster': 'dart', 'lambda': 1.5308394074991258e-08, 'alpha': 2.6422906304985136e-08, 'eta': 0.0014928783350560842, 'gamma': 2.6305271038380715e-07, 'max_depth': 8, 'n_estimators': 116, 'learning_rate': 8.162288549626736e-05, 'subsample': 0.3328758824130607, 'colsample_bytree': 0.11031127814156218}. Best is trial 2 with value: -316.90141149300024.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 14:41:37,900]\u001b[0m Trial 7 finished with value: -615.2368576470371 and parameters: {'booster': 'gbtree', 'lambda': 1.5529874811127854e-07, 'alpha': 0.0005630017491839261, 'eta': 7.862273681888664e-06, 'gamma': 1.04284111623669e-08, 'max_depth': 7, 'n_estimators': 140, 'learning_rate': 0.39739540435099535, 'subsample': 0.48594502982417853, 'colsample_bytree': 0.05804769618113396}. Best is trial 2 with value: -316.90141149300024.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training starts...\n",
      "fold_ 0  done !\n",
      "fold_ 1  done !\n",
      "fold_ 2  done !\n",
      "fold_ 3  done !\n",
      "fold_ 4  done !\n"
     ]
    }
   ],
   "source": [
    "train = Train(trainset, train_dhi, 'model_DHI_1')\n",
    "pred_df = train.train_loop()\n",
    "\n",
    "trainset['Clearsky DHI']  = pred_df['tar']\n",
    "convert_dict = {\"Clearsky DHI\":float}\n",
    "trainset = trainset.astype(convert_dict)\n",
    "\n",
    "pred_df.to_csv(\"oof_pred_DHI_1\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7ecb3bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-12T14:41:45.207124Z",
     "iopub.status.busy": "2023-04-12T14:41:45.206797Z",
     "iopub.status.idle": "2023-04-12T14:41:45.230695Z",
     "shell.execute_reply": "2023-04-12T14:41:45.229615Z"
    },
    "papermill": {
     "duration": 0.032981,
     "end_time": "2023-04-12T14:41:45.233232",
     "exception": false,
     "start_time": "2023-04-12T14:41:45.200251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>Cloud Type</th>\n",
       "      <th>Dew Point</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Pressure</th>\n",
       "      <th>Relative Humidity</th>\n",
       "      <th>Solar Zenith Angle</th>\n",
       "      <th>Precipitable Water</th>\n",
       "      <th>Wind Direction</th>\n",
       "      <th>Wind Speed</th>\n",
       "      <th>Fill Flag</th>\n",
       "      <th>Clearsky DHI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1010</td>\n",
       "      <td>75.34</td>\n",
       "      <td>106.15</td>\n",
       "      <td>0.499</td>\n",
       "      <td>346.1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.089561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1010</td>\n",
       "      <td>80.81</td>\n",
       "      <td>112.28</td>\n",
       "      <td>0.490</td>\n",
       "      <td>346.1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.026620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1010</td>\n",
       "      <td>78.27</td>\n",
       "      <td>118.50</td>\n",
       "      <td>0.482</td>\n",
       "      <td>347.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.154262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1010</td>\n",
       "      <td>78.27</td>\n",
       "      <td>124.78</td>\n",
       "      <td>0.478</td>\n",
       "      <td>347.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.839067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1010</td>\n",
       "      <td>76.45</td>\n",
       "      <td>131.12</td>\n",
       "      <td>0.475</td>\n",
       "      <td>350.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.736160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Month  Day  Hour  Minute  Cloud Type  Dew Point  Temperature  \\\n",
       "0  2009      1    1     0       0           0        0.0          5.0   \n",
       "1  2009      1    1     0      30           0        1.0          5.0   \n",
       "2  2009      1    1     1       0           4        0.0          5.0   \n",
       "3  2009      1    1     1      30           4        0.0          4.0   \n",
       "4  2009      1    1     2       0           4        0.0          4.0   \n",
       "\n",
       "   Pressure  Relative Humidity  Solar Zenith Angle  Precipitable Water  \\\n",
       "0      1010              75.34              106.15               0.499   \n",
       "1      1010              80.81              112.28               0.490   \n",
       "2      1010              78.27              118.50               0.482   \n",
       "3      1010              78.27              124.78               0.478   \n",
       "4      1010              76.45              131.12               0.475   \n",
       "\n",
       "   Wind Direction  Wind Speed  Fill Flag  Clearsky DHI  \n",
       "0           346.1         3.1          0     -0.089561  \n",
       "1           346.1         3.1          0     -0.026620  \n",
       "2           347.9         3.2          0      0.154262  \n",
       "3           347.9         3.1          0      2.839067  \n",
       "4           350.0         3.0          0      0.736160  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe1dc981",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-12T14:41:45.245332Z",
     "iopub.status.busy": "2023-04-12T14:41:45.245055Z",
     "iopub.status.idle": "2023-04-12T14:41:45.270027Z",
     "shell.execute_reply": "2023-04-12T14:41:45.268702Z"
    },
    "papermill": {
     "duration": 0.033786,
     "end_time": "2023-04-12T14:41:45.272332",
     "exception": false,
     "start_time": "2023-04-12T14:41:45.238546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 175296 entries, 0 to 175295\n",
      "Data columns (total 16 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   Year                175296 non-null  int64  \n",
      " 1   Month               175296 non-null  int64  \n",
      " 2   Day                 175296 non-null  int64  \n",
      " 3   Hour                175296 non-null  int64  \n",
      " 4   Minute              175296 non-null  int64  \n",
      " 5   Cloud Type          175296 non-null  int64  \n",
      " 6   Dew Point           175296 non-null  float64\n",
      " 7   Temperature         175296 non-null  float64\n",
      " 8   Pressure            175296 non-null  int64  \n",
      " 9   Relative Humidity   175296 non-null  float64\n",
      " 10  Solar Zenith Angle  175296 non-null  float64\n",
      " 11  Precipitable Water  175296 non-null  float64\n",
      " 12  Wind Direction      175296 non-null  float64\n",
      " 13  Wind Speed          175296 non-null  float64\n",
      " 14  Fill Flag           175296 non-null  int64  \n",
      " 15  Clearsky DHI        175296 non-null  float64\n",
      "dtypes: float64(8), int64(8)\n",
      "memory usage: 21.4 MB\n"
     ]
    }
   ],
   "source": [
    "trainset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe09cf89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-12T14:41:45.285033Z",
     "iopub.status.busy": "2023-04-12T14:41:45.284732Z",
     "iopub.status.idle": "2023-04-12T14:48:29.883275Z",
     "shell.execute_reply": "2023-04-12T14:48:29.882223Z"
    },
    "papermill": {
     "duration": 404.607743,
     "end_time": "2023-04-12T14:48:29.885777",
     "exception": false,
     "start_time": "2023-04-12T14:41:45.278034",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-12 14:41:45,295]\u001b[0m A new study created in memory with name: no-name-d8a67227-66b8-473f-a43d-433305c357f3\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 14:42:28,115]\u001b[0m Trial 0 finished with value: -165863.35703820185 and parameters: {'booster': 'gbtree', 'lambda': 0.01927563686102126, 'alpha': 0.0010027484854845357, 'eta': 0.013062705614748222, 'gamma': 0.003395159801941992, 'max_depth': 9, 'n_estimators': 198, 'learning_rate': 8.966155001496446e-05, 'subsample': 0.8743731506582699, 'colsample_bytree': 0.7632741482270398}. Best is trial 0 with value: -165863.35703820185.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 14:43:23,200]\u001b[0m Trial 1 finished with value: -654.1563625156328 and parameters: {'booster': 'gbtree', 'lambda': 0.0014465031126322933, 'alpha': 0.302156554458262, 'eta': 0.4071506202095619, 'gamma': 0.0035888255619629114, 'max_depth': 10, 'n_estimators': 156, 'learning_rate': 0.03692498666328662, 'subsample': 0.20302847169343302, 'colsample_bytree': 0.3474825444834563}. Best is trial 1 with value: -654.1563625156328.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 14:44:23,940]\u001b[0m Trial 2 finished with value: -206.09505858629467 and parameters: {'booster': 'dart', 'lambda': 0.0007233291353170243, 'alpha': 0.08889494344563482, 'eta': 8.447344524227579e-08, 'gamma': 3.304992187538364, 'max_depth': 8, 'n_estimators': 144, 'learning_rate': 0.025855512439812395, 'subsample': 0.42003489583626635, 'colsample_bytree': 0.6210838394376496}. Best is trial 2 with value: -206.09505858629467.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 14:44:28,979]\u001b[0m Trial 3 finished with value: -9813.721364739911 and parameters: {'booster': 'gbtree', 'lambda': 1.7193848087722407e-07, 'alpha': 0.014356067845146394, 'eta': 1.6725051254322443e-07, 'gamma': 2.243317104687738e-08, 'max_depth': 7, 'n_estimators': 148, 'learning_rate': 0.03797399741224812, 'subsample': 0.01981356094008284, 'colsample_bytree': 0.008244843968780498}. Best is trial 2 with value: -206.09505858629467.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 14:45:48,691]\u001b[0m Trial 4 finished with value: -56.44413451387387 and parameters: {'booster': 'dart', 'lambda': 0.003603839435174177, 'alpha': 0.847785976054015, 'eta': 8.577577413851828e-07, 'gamma': 3.05531005426237e-05, 'max_depth': 7, 'n_estimators': 181, 'learning_rate': 0.27945652863031595, 'subsample': 0.5487275401081664, 'colsample_bytree': 0.8680962781905853}. Best is trial 4 with value: -56.44413451387387.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 14:46:39,602]\u001b[0m Trial 5 finished with value: -13935.657104904754 and parameters: {'booster': 'dart', 'lambda': 0.0101234035907604, 'alpha': 0.0010469651946611086, 'eta': 0.0032284485613898388, 'gamma': 1.1902988990343348e-05, 'max_depth': 5, 'n_estimators': 151, 'learning_rate': 0.010021305086683238, 'subsample': 0.40890898487686445, 'colsample_bytree': 0.32669585184900474}. Best is trial 4 with value: -56.44413451387387.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 14:46:49,733]\u001b[0m Trial 6 finished with value: -160739.03701018443 and parameters: {'booster': 'gblinear', 'lambda': 5.528749126130301e-06, 'alpha': 0.002121221954768522, 'eta': 0.32228240682219855, 'gamma': 0.0036820451789102374, 'max_depth': 9, 'n_estimators': 122, 'learning_rate': 4.864437882149685e-05, 'subsample': 0.8592683469446024, 'colsample_bytree': 0.048600788548777175}. Best is trial 4 with value: -56.44413451387387.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 14:47:46,218]\u001b[0m Trial 7 finished with value: -99307.42664745287 and parameters: {'booster': 'gbtree', 'lambda': 1.2904268980398838e-07, 'alpha': 0.3001557767057459, 'eta': 4.3962063508776054e-08, 'gamma': 2.1643418228749083e-07, 'max_depth': 10, 'n_estimators': 134, 'learning_rate': 0.0020461454576098195, 'subsample': 0.7812976547739086, 'colsample_bytree': 0.9827712980275559}. Best is trial 4 with value: -56.44413451387387.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training starts...\n",
      "fold_ 0  done !\n",
      "fold_ 1  done !\n",
      "fold_ 2  done !\n",
      "fold_ 3  done !\n",
      "fold_ 4  done !\n"
     ]
    }
   ],
   "source": [
    "### trainset -> R+DHI\n",
    "train = Train(trainset, train_ghi, 'model_GHI_1')\n",
    "pred_df = train.train_loop()\n",
    "\n",
    "trainset['Clearsky GHI']  = pred_df['tar']\n",
    "convert_dict = {\"Clearsky GHI\":float}\n",
    "trainset = trainset.astype(convert_dict)\n",
    "\n",
    "pred_df.to_csv(\"oof_pred_GHI_1\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aad83596",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-12T14:48:29.899643Z",
     "iopub.status.busy": "2023-04-12T14:48:29.899330Z",
     "iopub.status.idle": "2023-04-12T14:48:29.917682Z",
     "shell.execute_reply": "2023-04-12T14:48:29.916719Z"
    },
    "papermill": {
     "duration": 0.027858,
     "end_time": "2023-04-12T14:48:29.920038",
     "exception": false,
     "start_time": "2023-04-12T14:48:29.892180",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>Cloud Type</th>\n",
       "      <th>Dew Point</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Pressure</th>\n",
       "      <th>Relative Humidity</th>\n",
       "      <th>Solar Zenith Angle</th>\n",
       "      <th>Precipitable Water</th>\n",
       "      <th>Wind Direction</th>\n",
       "      <th>Wind Speed</th>\n",
       "      <th>Fill Flag</th>\n",
       "      <th>Clearsky DHI</th>\n",
       "      <th>Clearsky GHI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1010</td>\n",
       "      <td>75.34</td>\n",
       "      <td>106.15</td>\n",
       "      <td>0.499</td>\n",
       "      <td>346.1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.089561</td>\n",
       "      <td>0.001780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1010</td>\n",
       "      <td>80.81</td>\n",
       "      <td>112.28</td>\n",
       "      <td>0.490</td>\n",
       "      <td>346.1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.026620</td>\n",
       "      <td>0.111337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1010</td>\n",
       "      <td>78.27</td>\n",
       "      <td>118.50</td>\n",
       "      <td>0.482</td>\n",
       "      <td>347.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.154262</td>\n",
       "      <td>-0.002060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1010</td>\n",
       "      <td>78.27</td>\n",
       "      <td>124.78</td>\n",
       "      <td>0.478</td>\n",
       "      <td>347.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.839067</td>\n",
       "      <td>-0.045307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1010</td>\n",
       "      <td>76.45</td>\n",
       "      <td>131.12</td>\n",
       "      <td>0.475</td>\n",
       "      <td>350.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.736160</td>\n",
       "      <td>-0.320229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Month  Day  Hour  Minute  Cloud Type  Dew Point  Temperature  \\\n",
       "0  2009      1    1     0       0           0        0.0          5.0   \n",
       "1  2009      1    1     0      30           0        1.0          5.0   \n",
       "2  2009      1    1     1       0           4        0.0          5.0   \n",
       "3  2009      1    1     1      30           4        0.0          4.0   \n",
       "4  2009      1    1     2       0           4        0.0          4.0   \n",
       "\n",
       "   Pressure  Relative Humidity  Solar Zenith Angle  Precipitable Water  \\\n",
       "0      1010              75.34              106.15               0.499   \n",
       "1      1010              80.81              112.28               0.490   \n",
       "2      1010              78.27              118.50               0.482   \n",
       "3      1010              78.27              124.78               0.478   \n",
       "4      1010              76.45              131.12               0.475   \n",
       "\n",
       "   Wind Direction  Wind Speed  Fill Flag  Clearsky DHI  Clearsky GHI  \n",
       "0           346.1         3.1          0     -0.089561      0.001780  \n",
       "1           346.1         3.1          0     -0.026620      0.111337  \n",
       "2           347.9         3.2          0      0.154262     -0.002060  \n",
       "3           347.9         3.1          0      2.839067     -0.045307  \n",
       "4           350.0         3.0          0      0.736160     -0.320229  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f4022a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-12T14:48:29.934476Z",
     "iopub.status.busy": "2023-04-12T14:48:29.933635Z",
     "iopub.status.idle": "2023-04-12T14:54:42.246186Z",
     "shell.execute_reply": "2023-04-12T14:54:42.245065Z"
    },
    "papermill": {
     "duration": 372.322681,
     "end_time": "2023-04-12T14:54:42.249041",
     "exception": false,
     "start_time": "2023-04-12T14:48:29.926360",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-12 14:48:29,943]\u001b[0m A new study created in memory with name: no-name-be1662c6-d127-48ba-b3a8-cd7cb48e06c8\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 14:49:06,012]\u001b[0m Trial 0 finished with value: -205309.74846057166 and parameters: {'booster': 'dart', 'lambda': 0.002286868760881918, 'alpha': 0.02276184766797106, 'eta': 8.194978887106593e-08, 'gamma': 0.05717420911022738, 'max_depth': 8, 'n_estimators': 106, 'learning_rate': 0.0009785302724657277, 'subsample': 0.23452414352504647, 'colsample_bytree': 0.244081834007176}. Best is trial 0 with value: -205309.74846057166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 14:50:08,412]\u001b[0m Trial 1 finished with value: -235315.9208585259 and parameters: {'booster': 'dart', 'lambda': 0.09454359216886249, 'alpha': 0.0005142653081430859, 'eta': 0.0003411046218554219, 'gamma': 0.02775492445852555, 'max_depth': 7, 'n_estimators': 155, 'learning_rate': 0.00014187626261200135, 'subsample': 0.7427221921070697, 'colsample_bytree': 0.46732249879248206}. Best is trial 0 with value: -205309.74846057166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 14:51:38,081]\u001b[0m Trial 2 finished with value: -221474.70792199904 and parameters: {'booster': 'dart', 'lambda': 0.03976015302453704, 'alpha': 2.8357926080829582e-05, 'eta': 1.756222731929546e-05, 'gamma': 0.0633819106749829, 'max_depth': 8, 'n_estimators': 195, 'learning_rate': 0.0004687495551021262, 'subsample': 0.6793961645588956, 'colsample_bytree': 0.054510353270557844}. Best is trial 0 with value: -205309.74846057166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 14:52:37,853]\u001b[0m Trial 3 finished with value: -11490.819186133242 and parameters: {'booster': 'gbtree', 'lambda': 0.04065714739811525, 'alpha': 0.00016469897337150012, 'eta': 2.0704682931429534e-07, 'gamma': 5.852804571723711e-06, 'max_depth': 10, 'n_estimators': 146, 'learning_rate': 0.010843573478271397, 'subsample': 0.987707747958882, 'colsample_bytree': 0.6793251334879458}. Best is trial 3 with value: -11490.819186133242.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 14:52:55,373]\u001b[0m Trial 4 finished with value: -14885.519729910822 and parameters: {'booster': 'gblinear', 'lambda': 0.04254158275163454, 'alpha': 0.0010071534169666968, 'eta': 0.13975638884732358, 'gamma': 2.8727578913562414e-06, 'max_depth': 5, 'n_estimators': 199, 'learning_rate': 0.1120116619782576, 'subsample': 0.5214939583348653, 'colsample_bytree': 0.46659866360486757}. Best is trial 3 with value: -11490.819186133242.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 14:53:04,902]\u001b[0m Trial 5 finished with value: -78153.11891819382 and parameters: {'booster': 'gblinear', 'lambda': 1.2583711472686527e-06, 'alpha': 0.000394295920326352, 'eta': 0.00665777115721443, 'gamma': 7.138007130179275e-06, 'max_depth': 8, 'n_estimators': 107, 'learning_rate': 0.0018763991680736376, 'subsample': 0.6610448934417413, 'colsample_bytree': 0.294090139202462}. Best is trial 3 with value: -11490.819186133242.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 14:53:14,456]\u001b[0m Trial 6 finished with value: -227535.2471047064 and parameters: {'booster': 'gblinear', 'lambda': 0.037889276536701245, 'alpha': 0.0015674730532870796, 'eta': 6.9540000010849525e-06, 'gamma': 2.2896976831596072e-05, 'max_depth': 7, 'n_estimators': 107, 'learning_rate': 4.925856736051879e-05, 'subsample': 0.9095130279529129, 'colsample_bytree': 0.7247570153293127}. Best is trial 3 with value: -11490.819186133242.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 14:54:11,177]\u001b[0m Trial 7 finished with value: -1055.0041501161136 and parameters: {'booster': 'dart', 'lambda': 0.013540542169369035, 'alpha': 1.3100283915272337e-07, 'eta': 0.0024439882670524026, 'gamma': 0.017192934219257463, 'max_depth': 5, 'n_estimators': 158, 'learning_rate': 0.06859515815670972, 'subsample': 0.23165881037314032, 'colsample_bytree': 0.6236048170955061}. Best is trial 7 with value: -1055.0041501161136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training starts...\n",
      "fold_ 0  done !\n",
      "fold_ 1  done !\n",
      "fold_ 2  done !\n",
      "fold_ 3  done !\n",
      "fold_ 4  done !\n"
     ]
    }
   ],
   "source": [
    "### trainset -> R+DHI+GHI\n",
    "train = Train(trainset, train_dni, 'model_DNI_1')\n",
    "pred_df = train.train_loop()\n",
    "\n",
    "trainset['Clearsky DNI']  = pred_df['tar']\n",
    "convert_dict = {\"Clearsky DNI\":float}\n",
    "trainset = trainset.astype(convert_dict)\n",
    "\n",
    "pred_df.to_csv(\"oof_pred_DNI_1\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c89dd935",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-12T14:54:42.265059Z",
     "iopub.status.busy": "2023-04-12T14:54:42.264731Z",
     "iopub.status.idle": "2023-04-12T14:58:52.135626Z",
     "shell.execute_reply": "2023-04-12T14:58:52.134513Z"
    },
    "papermill": {
     "duration": 249.881563,
     "end_time": "2023-04-12T14:58:52.138077",
     "exception": false,
     "start_time": "2023-04-12T14:54:42.256514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-12 14:54:42,294]\u001b[0m A new study created in memory with name: no-name-7c4cac69-3248-4aaf-b779-e6c8b1cfaf80\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:39:01] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:39:06] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:39:10] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:39:23] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:39:26] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:39:33] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:39:37] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:39:41] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:46:39] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:46:43] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:46:47] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:52:38] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:52:44] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:52:51] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:52:55] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:52:59] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:53:05] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:53:08] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:54:42] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:54:47] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "[14:39:01] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:39:06] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:39:23] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:39:26] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:39:30] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:39:33] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:39:37] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:46:39] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:46:43] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:52:38] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:52:44] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:52:55] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:52:59] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:53:02] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:53:05] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:53:08] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:53:12] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:54:42] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:54:47] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:54:51] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-12 14:54:54,969]\u001b[0m Trial 0 finished with value: -718.1727288376769 and parameters: {'booster': 'gblinear', 'lambda': 0.09582774137922452, 'alpha': 0.5509458853728786, 'eta': 0.035116302003519013, 'gamma': 8.184723658278211e-07, 'max_depth': 10, 'n_estimators': 143, 'learning_rate': 0.004513368426286492, 'subsample': 0.5011867993252058, 'colsample_bytree': 0.44752343717226256}. Best is trial 0 with value: -718.1727288376769.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 14:56:12,591]\u001b[0m Trial 1 finished with value: -6709.119975650765 and parameters: {'booster': 'dart', 'lambda': 0.2293655812450268, 'alpha': 5.210666485568893e-06, 'eta': 0.03702580624828988, 'gamma': 2.230735764796613e-08, 'max_depth': 5, 'n_estimators': 185, 'learning_rate': 7.519314698827544e-05, 'subsample': 0.6098386649569929, 'colsample_bytree': 0.38975342772425114}. Best is trial 0 with value: -718.1727288376769.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 14:56:29,151]\u001b[0m Trial 2 finished with value: -1495.5094005407068 and parameters: {'booster': 'gblinear', 'lambda': 3.056134905413133e-08, 'alpha': 2.2659507709363074e-05, 'eta': 0.04584992035185114, 'gamma': 1.1836135282936796e-07, 'max_depth': 5, 'n_estimators': 193, 'learning_rate': 0.001710941646811457, 'subsample': 0.7672710135632544, 'colsample_bytree': 0.05885141587326029}. Best is trial 0 with value: -718.1727288376769.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 14:57:22,499]\u001b[0m Trial 3 finished with value: -220.3053563245753 and parameters: {'booster': 'dart', 'lambda': 2.104028383763229e-05, 'alpha': 0.000731876861584466, 'eta': 0.0032045630816258095, 'gamma': 0.017415279462518713, 'max_depth': 7, 'n_estimators': 146, 'learning_rate': 0.3398313910055101, 'subsample': 0.20479028075195674, 'colsample_bytree': 0.7009949904665181}. Best is trial 3 with value: -220.3053563245753.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 14:57:49,636]\u001b[0m Trial 4 finished with value: -2611.7025608139893 and parameters: {'booster': 'gbtree', 'lambda': 1.4378552101289944e-08, 'alpha': 2.3035782765856294e-07, 'eta': 0.0001293093930801757, 'gamma': 0.3156951915379721, 'max_depth': 9, 'n_estimators': 147, 'learning_rate': 0.004437884867100121, 'subsample': 0.16151405318373363, 'colsample_bytree': 0.202672505243745}. Best is trial 3 with value: -220.3053563245753.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 14:58:05,119]\u001b[0m Trial 5 finished with value: -183.08828322620428 and parameters: {'booster': 'gblinear', 'lambda': 0.053361927497826145, 'alpha': 1.0085314896646825e-08, 'eta': 7.185790753912045e-06, 'gamma': 0.0026679651224144458, 'max_depth': 5, 'n_estimators': 179, 'learning_rate': 0.01304146532468148, 'subsample': 0.5251893042276625, 'colsample_bytree': 0.19322017021282722}. Best is trial 5 with value: -183.08828322620428.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 14:58:21,112]\u001b[0m Trial 6 finished with value: -5223.467787352479 and parameters: {'booster': 'gblinear', 'lambda': 5.317136537877781e-06, 'alpha': 0.048195662601549075, 'eta': 0.0008915142187367115, 'gamma': 0.00028133084646366304, 'max_depth': 10, 'n_estimators': 187, 'learning_rate': 0.00011173605784496062, 'subsample': 0.5656662709847005, 'colsample_bytree': 0.9100180718291881}. Best is trial 5 with value: -183.08828322620428.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 14:58:35,869]\u001b[0m Trial 7 finished with value: -188.04400266432663 and parameters: {'booster': 'gblinear', 'lambda': 0.41167925472956846, 'alpha': 5.0309673723913676e-05, 'eta': 0.5028173790257618, 'gamma': 0.7286912636563535, 'max_depth': 5, 'n_estimators': 171, 'learning_rate': 0.011367813638672203, 'subsample': 0.10708746764974525, 'colsample_bytree': 0.4446217065950717}. Best is trial 5 with value: -183.08828322620428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training starts...\n",
      "fold_ 0  done !\n",
      "[14:58:35] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "fold_ 1  done !\n",
      "[14:58:39] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "fold_ 2  done !\n",
      "[14:58:42] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "fold_ 3  done !\n",
      "[14:58:45] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "fold_ 4  done !\n",
      "[14:58:48] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainset = trainset.drop(['Clearsky DHI'], axis = 1)\n",
    "### trainset -> R+GHI+DNI\n",
    "train = Train(trainset, train_dhi, 'model_DHI_2')\n",
    "pred_df = train.train_loop()\n",
    "\n",
    "trainset['Clearsky DHI']  = pred_df['tar']\n",
    "convert_dict = {\"Clearsky DHI\":float}\n",
    "trainset = trainset.astype(convert_dict)\n",
    "\n",
    "pred_df.to_csv(\"oof_pred_DHI_2\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8cd262e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-12T14:58:52.156632Z",
     "iopub.status.busy": "2023-04-12T14:58:52.156006Z",
     "iopub.status.idle": "2023-04-12T15:07:53.192417Z",
     "shell.execute_reply": "2023-04-12T15:07:53.191377Z"
    },
    "papermill": {
     "duration": 541.04862,
     "end_time": "2023-04-12T15:07:53.195362",
     "exception": false,
     "start_time": "2023-04-12T14:58:52.146742",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-12 14:58:52,186]\u001b[0m A new study created in memory with name: no-name-83fa3b06-2a59-43ce-8a9f-3c7a3f5e4af1\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 15:00:05,824]\u001b[0m Trial 0 finished with value: -69.61190069434764 and parameters: {'booster': 'dart', 'lambda': 0.09610749263322142, 'alpha': 0.7749943320238222, 'eta': 0.003869409109301468, 'gamma': 1.1434942752668794e-08, 'max_depth': 8, 'n_estimators': 163, 'learning_rate': 0.4044220498966254, 'subsample': 0.911547202164159, 'colsample_bytree': 0.6055350280553088}. Best is trial 0 with value: -69.61190069434764.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 15:00:42,932]\u001b[0m Trial 1 finished with value: -111.79171907145053 and parameters: {'booster': 'dart', 'lambda': 0.12139804795742189, 'alpha': 0.0009974262408564796, 'eta': 0.00010005025550394787, 'gamma': 0.009371878445425098, 'max_depth': 6, 'n_estimators': 123, 'learning_rate': 0.06672078441641759, 'subsample': 0.8009826546437288, 'colsample_bytree': 0.4219984276793158}. Best is trial 0 with value: -69.61190069434764.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 15:02:22,550]\u001b[0m Trial 2 finished with value: -15141.57207574533 and parameters: {'booster': 'dart', 'lambda': 0.0022890129061047325, 'alpha': 1.3946549281945421e-05, 'eta': 0.6348070584104094, 'gamma': 1.20799452164214e-06, 'max_depth': 8, 'n_estimators': 194, 'learning_rate': 0.012033459998810973, 'subsample': 0.21825662161518045, 'colsample_bytree': 0.16960404228276224}. Best is trial 0 with value: -69.61190069434764.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 15:03:04,461]\u001b[0m Trial 3 finished with value: -5093.589157034628 and parameters: {'booster': 'dart', 'lambda': 0.8471424419101052, 'alpha': 0.018444172937275093, 'eta': 0.00010342189430857522, 'gamma': 2.5785607069702094, 'max_depth': 10, 'n_estimators': 128, 'learning_rate': 0.05270801434632936, 'subsample': 0.4000265633387236, 'colsample_bytree': 0.012792615262897438}. Best is trial 0 with value: -69.61190069434764.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 15:04:44,848]\u001b[0m Trial 4 finished with value: -116821.37693140288 and parameters: {'booster': 'dart', 'lambda': 1.3453586221955532e-05, 'alpha': 0.003602349935154266, 'eta': 0.06541234899730049, 'gamma': 5.6932836159755696e-05, 'max_depth': 8, 'n_estimators': 191, 'learning_rate': 0.0010262765338237673, 'subsample': 0.32453182723885465, 'colsample_bytree': 0.5571050333372398}. Best is trial 0 with value: -69.61190069434764.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 15:04:56,356]\u001b[0m Trial 5 finished with value: -22035.690803569683 and parameters: {'booster': 'gblinear', 'lambda': 0.0037454807778946396, 'alpha': 2.3617538938930108e-08, 'eta': 0.024389064712935393, 'gamma': 0.2728392532770403, 'max_depth': 9, 'n_estimators': 133, 'learning_rate': 0.11653288024046562, 'subsample': 0.462594252890391, 'colsample_bytree': 0.023760981960536783}. Best is trial 0 with value: -69.61190069434764.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 15:05:11,225]\u001b[0m Trial 6 finished with value: -1491.1223878119902 and parameters: {'booster': 'gbtree', 'lambda': 2.9296183489362454e-08, 'alpha': 0.02459508608803277, 'eta': 0.2511539594666783, 'gamma': 5.864038079286912, 'max_depth': 9, 'n_estimators': 102, 'learning_rate': 0.08878965224631631, 'subsample': 0.8519733098996934, 'colsample_bytree': 0.12469758926785417}. Best is trial 0 with value: -69.61190069434764.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 15:07:10,872]\u001b[0m Trial 7 finished with value: -2086.523148228617 and parameters: {'booster': 'dart', 'lambda': 2.934796031421947e-06, 'alpha': 8.678392058372013e-05, 'eta': 0.004734903371710401, 'gamma': 1.0425873814774163e-07, 'max_depth': 10, 'n_estimators': 184, 'learning_rate': 0.03693832610691353, 'subsample': 0.5199065851590645, 'colsample_bytree': 0.17412417733518698}. Best is trial 0 with value: -69.61190069434764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training starts...\n",
      "fold_ 0  done !\n",
      "fold_ 1  done !\n",
      "fold_ 2  done !\n",
      "fold_ 3  done !\n",
      "fold_ 4  done !\n"
     ]
    }
   ],
   "source": [
    "trainset = trainset.drop(['Clearsky GHI'], axis = 1)\n",
    "### trainset -> R+DHI+DNI\n",
    "train = Train(trainset, train_ghi, 'model_GHI_2')\n",
    "pred_df = train.train_loop()\n",
    "\n",
    "trainset['Clearsky GHI']  = pred_df['tar']\n",
    "convert_dict = {\"Clearsky GHI\":float}\n",
    "trainset = trainset.astype(convert_dict)\n",
    "\n",
    "pred_df.to_csv(\"oof_pred_GHI_2\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cffc465a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-12T15:07:53.215618Z",
     "iopub.status.busy": "2023-04-12T15:07:53.215314Z",
     "iopub.status.idle": "2023-04-12T15:11:15.344478Z",
     "shell.execute_reply": "2023-04-12T15:11:15.343461Z"
    },
    "papermill": {
     "duration": 202.141883,
     "end_time": "2023-04-12T15:11:15.347016",
     "exception": false,
     "start_time": "2023-04-12T15:07:53.205133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-12 15:07:53,244]\u001b[0m A new study created in memory with name: no-name-e979c3e2-46d6-4065-a411-0f4eea174121\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 15:08:00,662]\u001b[0m Trial 0 finished with value: -955.7183088759908 and parameters: {'booster': 'gbtree', 'lambda': 1.0616672661795683e-05, 'alpha': 0.0035816041364473343, 'eta': 0.4664903479570602, 'gamma': 0.020082850000645226, 'max_depth': 7, 'n_estimators': 119, 'learning_rate': 0.09970786552010218, 'subsample': 0.4269515497959054, 'colsample_bytree': 0.8183051714692066}. Best is trial 0 with value: -955.7183088759908.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 15:08:12,375]\u001b[0m Trial 1 finished with value: -18085.335421893 and parameters: {'booster': 'gblinear', 'lambda': 0.0011178694946209252, 'alpha': 1.2318079154389973e-06, 'eta': 0.03723925832322917, 'gamma': 7.408671748862204e-07, 'max_depth': 9, 'n_estimators': 132, 'learning_rate': 0.269213830677103, 'subsample': 0.6958557051079624, 'colsample_bytree': 0.8887906242692927}. Best is trial 0 with value: -955.7183088759908.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 15:08:37,784]\u001b[0m Trial 2 finished with value: -188974.68831284437 and parameters: {'booster': 'gbtree', 'lambda': 2.1562763313513365e-07, 'alpha': 0.0013379503711109415, 'eta': 0.9334756063666064, 'gamma': 8.206179157753354, 'max_depth': 9, 'n_estimators': 121, 'learning_rate': 0.0011303909783271161, 'subsample': 0.4450892780900576, 'colsample_bytree': 0.37163748679498554}. Best is trial 0 with value: -955.7183088759908.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 15:08:43,723]\u001b[0m Trial 3 finished with value: -121751.46452488886 and parameters: {'booster': 'gbtree', 'lambda': 1.884099300856525e-08, 'alpha': 0.000381917570531265, 'eta': 4.248392494205163e-07, 'gamma': 3.2802625406187337e-05, 'max_depth': 6, 'n_estimators': 164, 'learning_rate': 0.0021673257926068707, 'subsample': 0.014413191894990464, 'colsample_bytree': 0.8213286849016718}. Best is trial 0 with value: -955.7183088759908.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 15:10:14,340]\u001b[0m Trial 4 finished with value: -175426.1136371906 and parameters: {'booster': 'dart', 'lambda': 0.05064519775548425, 'alpha': 0.0019755772920820305, 'eta': 0.0005608716743640093, 'gamma': 0.07781718048240875, 'max_depth': 6, 'n_estimators': 197, 'learning_rate': 0.0008646665126134192, 'subsample': 0.74690759195566, 'colsample_bytree': 0.7159402316219321}. Best is trial 0 with value: -955.7183088759908.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[14:56:12] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:56:18] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:57:49] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:57:55] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:58:01] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:58:05] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:58:11] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:58:17] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:58:21] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:58:26] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:58:32] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:04:45] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:04:49] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:04:53] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:08:00] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:08:04] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:08:09] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:10:14] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:10:19] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:10:24] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-12 15:10:27,661]\u001b[0m Trial 5 finished with value: -38155.12533035218 and parameters: {'booster': 'gblinear', 'lambda': 1.1288610696400487e-05, 'alpha': 0.00010913045979237252, 'eta': 6.868043720054991e-08, 'gamma': 3.7374934234345536e-05, 'max_depth': 5, 'n_estimators': 149, 'learning_rate': 0.0044396359359289575, 'subsample': 0.6988640135609904, 'colsample_bytree': 0.6447821221925454}. Best is trial 0 with value: -955.7183088759908.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 15:11:01,047]\u001b[0m Trial 6 finished with value: -242186.62094303803 and parameters: {'booster': 'gbtree', 'lambda': 1.1940163820791017e-08, 'alpha': 0.005047326009898305, 'eta': 0.2028793860323499, 'gamma': 0.05738126503405069, 'max_depth': 10, 'n_estimators': 153, 'learning_rate': 6.392111938377506e-05, 'subsample': 0.3413082681510625, 'colsample_bytree': 0.12363647751998515}. Best is trial 0 with value: -955.7183088759908.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 15:11:10,510]\u001b[0m Trial 7 finished with value: -17916.138999820014 and parameters: {'booster': 'gblinear', 'lambda': 3.9119917167371255e-05, 'alpha': 5.136157764893078e-05, 'eta': 0.2272568310787717, 'gamma': 6.356572823458759e-07, 'max_depth': 7, 'n_estimators': 107, 'learning_rate': 0.4344686174016119, 'subsample': 0.49183474158161283, 'colsample_bytree': 0.6472687940378867}. Best is trial 0 with value: -955.7183088759908.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training starts...\n",
      "fold_ 0  done !\n",
      "fold_ 1  done !\n",
      "fold_ 2  done !\n",
      "fold_ 3  done !\n",
      "fold_ 4  done !\n"
     ]
    }
   ],
   "source": [
    "trainset = trainset.drop(['Clearsky DNI'], axis = 1)\n",
    "### trainset -> R+DHI+GHI\n",
    "train = Train(trainset, train_dni, 'model_DNI_2')\n",
    "pred_df = train.train_loop()\n",
    "\n",
    "trainset['Clearsky DNI']  = pred_df['tar']\n",
    "convert_dict = {\"Clearsky DNI\":float}\n",
    "trainset = trainset.astype(convert_dict)\n",
    "\n",
    "pred_df.to_csv(\"oof_pred_DNI_2\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1ec174b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-12T15:11:15.370312Z",
     "iopub.status.busy": "2023-04-12T15:11:15.368684Z",
     "iopub.status.idle": "2023-04-12T15:17:06.730719Z",
     "shell.execute_reply": "2023-04-12T15:17:06.729617Z"
    },
    "papermill": {
     "duration": 351.375924,
     "end_time": "2023-04-12T15:17:06.733225",
     "exception": false,
     "start_time": "2023-04-12T15:11:15.357301",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-12 15:11:15,400]\u001b[0m A new study created in memory with name: no-name-4bc86a8a-7815-496f-be8b-985e30c4d95c\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 15:12:59,152]\u001b[0m Trial 0 finished with value: -6761.624820359255 and parameters: {'booster': 'dart', 'lambda': 1.0028716686948123e-06, 'alpha': 0.07978480016273361, 'eta': 0.26274640114447206, 'gamma': 6.5323935003084e-07, 'max_depth': 9, 'n_estimators': 176, 'learning_rate': 5.229310716390823e-05, 'subsample': 0.9012597599632457, 'colsample_bytree': 0.9429471409894913}. Best is trial 0 with value: -6761.624820359255.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 15:14:03,395]\u001b[0m Trial 1 finished with value: -4142.102903554947 and parameters: {'booster': 'dart', 'lambda': 4.796092733577649e-07, 'alpha': 0.002712144551292186, 'eta': 0.0327073268255046, 'gamma': 1.2167069788549026e-05, 'max_depth': 8, 'n_estimators': 161, 'learning_rate': 0.0032347031820623624, 'subsample': 0.7020679914622521, 'colsample_bytree': 0.08751573087234038}. Best is trial 1 with value: -4142.102903554947.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[14:56:12] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:56:18] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:56:24] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:57:49] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:57:55] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:58:05] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:58:11] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:58:21] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:58:26] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:04:45] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:04:49] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:08:00] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:08:05] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:10:14] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:10:19] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:11:01] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:11:04] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:11:08] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:14:03] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:14:07] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-12 15:14:13,712]\u001b[0m Trial 2 finished with value: -101.11992530731318 and parameters: {'booster': 'gblinear', 'lambda': 0.3382976121828497, 'alpha': 3.496384279736765e-05, 'eta': 9.344829193132588e-07, 'gamma': 0.00053383563178997, 'max_depth': 6, 'n_estimators': 118, 'learning_rate': 0.6152228708612097, 'subsample': 0.2899027647551453, 'colsample_bytree': 0.7170146164739789}. Best is trial 2 with value: -101.11992530731318.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 15:14:30,228]\u001b[0m Trial 3 finished with value: -245.7077141722296 and parameters: {'booster': 'gblinear', 'lambda': 0.002801653149631, 'alpha': 6.28211887503714e-07, 'eta': 0.00019503768384429918, 'gamma': 4.8956756275431735e-05, 'max_depth': 6, 'n_estimators': 195, 'learning_rate': 0.00663970330006605, 'subsample': 0.7277058932713151, 'colsample_bytree': 0.35479750638639007}. Best is trial 2 with value: -101.11992530731318.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 15:15:24,380]\u001b[0m Trial 4 finished with value: -6097.819935075784 and parameters: {'booster': 'dart', 'lambda': 0.09975621836192715, 'alpha': 1.235573462279065e-06, 'eta': 1.3989730285571219e-07, 'gamma': 6.31558416617119, 'max_depth': 7, 'n_estimators': 145, 'learning_rate': 0.00042700018581877933, 'subsample': 0.5758348360076027, 'colsample_bytree': 0.8312143326201127}. Best is trial 2 with value: -101.11992530731318.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 15:15:41,234]\u001b[0m Trial 5 finished with value: -3422.834488705096 and parameters: {'booster': 'gblinear', 'lambda': 1.5644668814933538e-05, 'alpha': 0.021741693198396327, 'eta': 1.4975842720471978e-08, 'gamma': 0.014781619407264331, 'max_depth': 10, 'n_estimators': 193, 'learning_rate': 0.00035358499890715897, 'subsample': 0.08059691744435493, 'colsample_bytree': 0.5275105130122538}. Best is trial 2 with value: -101.11992530731318.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 15:16:38,879]\u001b[0m Trial 6 finished with value: -6707.55008790083 and parameters: {'booster': 'dart', 'lambda': 9.83152546576726e-05, 'alpha': 6.899180641979796e-06, 'eta': 1.497034479702557e-06, 'gamma': 0.010337475108579339, 'max_depth': 9, 'n_estimators': 123, 'learning_rate': 0.00011071165673232421, 'subsample': 0.24198660724263366, 'colsample_bytree': 0.4373119661304682}. Best is trial 2 with value: -101.11992530731318.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 15:16:56,005]\u001b[0m Trial 7 finished with value: -1575.849641065744 and parameters: {'booster': 'gblinear', 'lambda': 1.2210142314499398e-06, 'alpha': 0.20600218904137585, 'eta': 8.924582355188856e-08, 'gamma': 0.0625593549148839, 'max_depth': 9, 'n_estimators': 191, 'learning_rate': 0.0015903997272144375, 'subsample': 0.07628908973966377, 'colsample_bytree': 0.8031798534572631}. Best is trial 2 with value: -101.11992530731318.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training starts...\n",
      "fold_ 0  done !\n",
      "[15:16:56] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "fold_ 1  done !\n",
      "[15:16:58] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "fold_ 2  done !\n",
      "[15:17:00] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "fold_ 3  done !\n",
      "[15:17:02] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "fold_ 4  done !\n",
      "[15:17:04] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"predictor\", \"subsample\", \"tree_method\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainset = trainset.drop(['Clearsky DHI'], axis = 1)\n",
    "### trainset -> R+GHI+DNI\n",
    "train = Train(trainset, train_dhi, 'model_DHI_3')\n",
    "pred_df = train.train_loop()\n",
    "\n",
    "trainset['Clearsky DHI']  = pred_df['tar']\n",
    "convert_dict = {\"Clearsky DHI\":float}\n",
    "trainset = trainset.astype(convert_dict)\n",
    "\n",
    "pred_df.to_csv(\"oof_pred_DHI_3\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f201f9a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-12T15:17:06.757487Z",
     "iopub.status.busy": "2023-04-12T15:17:06.756591Z",
     "iopub.status.idle": "2023-04-12T15:19:09.754909Z",
     "shell.execute_reply": "2023-04-12T15:19:09.753807Z"
    },
    "papermill": {
     "duration": 123.012717,
     "end_time": "2023-04-12T15:19:09.757460",
     "exception": false,
     "start_time": "2023-04-12T15:17:06.744743",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-12 15:17:06,786]\u001b[0m A new study created in memory with name: no-name-47b986df-c78d-4d2f-b9de-080c71fa9343\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 15:17:19,423]\u001b[0m Trial 0 finished with value: -25107.325957534144 and parameters: {'booster': 'gblinear', 'lambda': 3.5972336409974322e-06, 'alpha': 0.001465463536995171, 'eta': 3.00181490996751e-07, 'gamma': 0.008419641880083121, 'max_depth': 6, 'n_estimators': 136, 'learning_rate': 0.049072402731112436, 'subsample': 0.11098389400451483, 'colsample_bytree': 0.38874256946219427}. Best is trial 0 with value: -25107.325957534144.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 15:17:49,159]\u001b[0m Trial 1 finished with value: -773.0514653487398 and parameters: {'booster': 'gbtree', 'lambda': 0.03289301013633662, 'alpha': 0.005379768247142283, 'eta': 2.3611285623069776e-06, 'gamma': 0.00045651793869910855, 'max_depth': 9, 'n_estimators': 162, 'learning_rate': 0.33576601901105807, 'subsample': 0.670383939252285, 'colsample_bytree': 0.45016346125709295}. Best is trial 1 with value: -773.0514653487398.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 15:17:58,028]\u001b[0m Trial 2 finished with value: -71.25395694960343 and parameters: {'booster': 'gbtree', 'lambda': 0.0001798654613370262, 'alpha': 6.174231525797981e-08, 'eta': 2.4558530174489285e-06, 'gamma': 1.3483009439490098e-06, 'max_depth': 7, 'n_estimators': 144, 'learning_rate': 0.12118850816135243, 'subsample': 0.22012591413658636, 'colsample_bytree': 0.5202854512505719}. Best is trial 2 with value: -71.25395694960343.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 15:18:04,215]\u001b[0m Trial 3 finished with value: -165896.16621494913 and parameters: {'booster': 'gbtree', 'lambda': 0.00013442310220904022, 'alpha': 2.243625851749825e-05, 'eta': 7.599828685033575e-06, 'gamma': 0.15124711460935986, 'max_depth': 6, 'n_estimators': 167, 'learning_rate': 0.00010846789009881305, 'subsample': 0.6632597550160354, 'colsample_bytree': 0.49629324102920275}. Best is trial 2 with value: -71.25395694960343.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 15:18:52,204]\u001b[0m Trial 4 finished with value: -160527.15684478285 and parameters: {'booster': 'dart', 'lambda': 0.8256383361239162, 'alpha': 0.31358069096431523, 'eta': 5.065708874490444e-08, 'gamma': 6.994279635782362e-06, 'max_depth': 7, 'n_estimators': 135, 'learning_rate': 0.00025368790674107144, 'subsample': 0.7266986129584416, 'colsample_bytree': 0.8323795061957249}. Best is trial 2 with value: -71.25395694960343.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 15:18:54,867]\u001b[0m Trial 5 finished with value: -39.523438435500886 and parameters: {'booster': 'gbtree', 'lambda': 3.2722809570508755e-08, 'alpha': 1.1436421928059671e-08, 'eta': 3.4438438693549057e-06, 'gamma': 0.0011857220066671492, 'max_depth': 5, 'n_estimators': 100, 'learning_rate': 0.26720342365963606, 'subsample': 0.6238988488715971, 'colsample_bytree': 0.8066262230703292}. Best is trial 5 with value: -39.523438435500886.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 15:19:00,921]\u001b[0m Trial 6 finished with value: -169793.69542162243 and parameters: {'booster': 'gbtree', 'lambda': 5.80594731123364e-08, 'alpha': 0.24059899245863967, 'eta': 0.0012344078555889748, 'gamma': 5.972458690881685e-05, 'max_depth': 6, 'n_estimators': 162, 'learning_rate': 3.730602297660656e-05, 'subsample': 0.24729539510520032, 'colsample_bytree': 0.7105500209272531}. Best is trial 5 with value: -39.523438435500886.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 15:19:07,649]\u001b[0m Trial 7 finished with value: -142277.93462908518 and parameters: {'booster': 'gbtree', 'lambda': 3.321954341415085e-08, 'alpha': 2.1677871984828564e-05, 'eta': 1.3418240449666533e-07, 'gamma': 0.08577080360767687, 'max_depth': 6, 'n_estimators': 183, 'learning_rate': 0.000530669332308484, 'subsample': 0.4026458225937931, 'colsample_bytree': 0.501652803564951}. Best is trial 5 with value: -39.523438435500886.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training starts...\n",
      "fold_ 0  done !\n",
      "fold_ 1  done !\n",
      "fold_ 2  done !\n",
      "fold_ 3  done !\n",
      "fold_ 4  done !\n"
     ]
    }
   ],
   "source": [
    "trainset = trainset.drop(['Clearsky GHI'], axis = 1)\n",
    "### trainset -> R+DHI+DNI\n",
    "train = Train(trainset, train_ghi, 'model_GHI_3')\n",
    "pred_df = train.train_loop()\n",
    "\n",
    "trainset['Clearsky GHI']  = pred_df['tar']\n",
    "convert_dict = {\"Clearsky GHI\":float}\n",
    "trainset = trainset.astype(convert_dict)\n",
    "\n",
    "pred_df.to_csv(\"oof_pred_GHI_3\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0044672e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-12T15:19:09.783034Z",
     "iopub.status.busy": "2023-04-12T15:19:09.782709Z",
     "iopub.status.idle": "2023-04-12T15:25:41.834983Z",
     "shell.execute_reply": "2023-04-12T15:25:41.833939Z"
    },
    "papermill": {
     "duration": 392.067606,
     "end_time": "2023-04-12T15:25:41.837490",
     "exception": false,
     "start_time": "2023-04-12T15:19:09.769884",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-12 15:19:09,813]\u001b[0m A new study created in memory with name: no-name-c6c829ae-6821-4569-a2f5-6bdda2e4a21f\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 15:19:41,224]\u001b[0m Trial 0 finished with value: -2402.220949915069 and parameters: {'booster': 'gbtree', 'lambda': 1.1796685892433106e-08, 'alpha': 0.0012953407157937087, 'eta': 5.6764390891731574e-08, 'gamma': 6.6424656505621496e-06, 'max_depth': 10, 'n_estimators': 111, 'learning_rate': 0.47236325937711365, 'subsample': 0.4885335344541809, 'colsample_bytree': 0.5661775176409498}. Best is trial 0 with value: -2402.220949915069.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 15:19:57,360]\u001b[0m Trial 1 finished with value: -121619.26023947392 and parameters: {'booster': 'gblinear', 'lambda': 6.7773074957478e-07, 'alpha': 0.13779478544664447, 'eta': 0.002660362952624295, 'gamma': 3.0583162533574746e-06, 'max_depth': 7, 'n_estimators': 181, 'learning_rate': 0.0003904737496215719, 'subsample': 0.29231672101630296, 'colsample_bytree': 0.4305900316203956}. Best is trial 0 with value: -2402.220949915069.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 15:21:04,342]\u001b[0m Trial 2 finished with value: -1057.3225079704966 and parameters: {'booster': 'dart', 'lambda': 0.8225089200767994, 'alpha': 4.127552606819609e-06, 'eta': 4.2363370278226606e-05, 'gamma': 1.2359052684095724, 'max_depth': 5, 'n_estimators': 171, 'learning_rate': 0.28489427934686923, 'subsample': 0.3224367003288035, 'colsample_bytree': 0.904238054190447}. Best is trial 2 with value: -1057.3225079704966.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 15:22:39,129]\u001b[0m Trial 3 finished with value: -240311.6949385566 and parameters: {'booster': 'dart', 'lambda': 0.0043543905522737585, 'alpha': 2.9548061182639395e-08, 'eta': 8.527121890847626e-07, 'gamma': 0.0003749690189753888, 'max_depth': 9, 'n_estimators': 165, 'learning_rate': 6.556751411105596e-05, 'subsample': 0.9806938015333325, 'colsample_bytree': 0.8718980393995988}. Best is trial 2 with value: -1057.3225079704966.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 15:24:05,138]\u001b[0m Trial 4 finished with value: -189379.39887126937 and parameters: {'booster': 'dart', 'lambda': 3.868421241091933e-08, 'alpha': 0.0014176031075996342, 'eta': 0.10914713311243546, 'gamma': 4.499813063388403e-05, 'max_depth': 10, 'n_estimators': 132, 'learning_rate': 0.000989602773226188, 'subsample': 0.0969465397122145, 'colsample_bytree': 0.9532142628130396}. Best is trial 2 with value: -1057.3225079704966.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 15:24:16,962]\u001b[0m Trial 5 finished with value: -942.3809358783252 and parameters: {'booster': 'gbtree', 'lambda': 0.006155217046573342, 'alpha': 0.0023999410125892986, 'eta': 3.5816758920369565e-05, 'gamma': 0.0299219936419518, 'max_depth': 8, 'n_estimators': 120, 'learning_rate': 0.06011955926583809, 'subsample': 0.3119409758077716, 'colsample_bytree': 0.959759025122903}. Best is trial 5 with value: -942.3809358783252.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 15:25:30,876]\u001b[0m Trial 6 finished with value: -227287.08473477443 and parameters: {'booster': 'dart', 'lambda': 3.644081215270528e-05, 'alpha': 0.014821696331148698, 'eta': 4.213225985471934e-05, 'gamma': 7.280603756208361e-07, 'max_depth': 7, 'n_estimators': 178, 'learning_rate': 0.00038047042710996555, 'subsample': 0.9037163478996655, 'colsample_bytree': 0.014733688423967757}. Best is trial 5 with value: -942.3809358783252.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 15:25:33,953]\u001b[0m Trial 7 finished with value: -231158.23725428595 and parameters: {'booster': 'gbtree', 'lambda': 0.007947365429138755, 'alpha': 5.279394159269405e-07, 'eta': 1.4101663604715703e-07, 'gamma': 0.03398280029875654, 'max_depth': 5, 'n_estimators': 123, 'learning_rate': 0.00028191847045874236, 'subsample': 0.27091299568873145, 'colsample_bytree': 0.24657456380062046}. Best is trial 5 with value: -942.3809358783252.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training starts...\n",
      "fold_ 0  done !\n",
      "fold_ 1  done !\n",
      "fold_ 2  done !\n",
      "fold_ 3  done !\n",
      "fold_ 4  done !\n"
     ]
    }
   ],
   "source": [
    "trainset = trainset.drop(['Clearsky DNI'], axis = 1)\n",
    "### trainset -> R+DHI+GHI\n",
    "train = Train(trainset, train_dni, 'model_DNI_3')\n",
    "pred_df = train.train_loop()\n",
    "\n",
    "trainset['Clearsky DNI']  = pred_df['tar']\n",
    "convert_dict = {\"Clearsky DNI\":float}\n",
    "trainset = trainset.astype(convert_dict)\n",
    "\n",
    "pred_df.to_csv(\"oof_pred_DNI_3\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3ade03",
   "metadata": {
    "papermill": {
     "duration": 0.013006,
     "end_time": "2023-04-12T15:25:41.863794",
     "exception": false,
     "start_time": "2023-04-12T15:25:41.850788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2856.490329,
   "end_time": "2023-04-12T15:25:44.608047",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-04-12T14:38:08.117718",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
